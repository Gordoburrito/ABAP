#!/usr/bin/env python3
"""
Test runner script for Steele data transformation pipeline.
Demonstrates Test-Driven Development workflow with proper data flow:
Sample Data â†’ Golden Master â†’ AI-Friendly Format â†’ Final Tagged Format
"""

import subprocess
import sys
import os
from pathlib import Path

def run_command(cmd, description):
    """Run a command and print results"""
    print(f"\n{'='*60}")
    print(f"ğŸ”„ {description}")
    print('='*60)
    
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, cwd=Path(__file__).parent)
        
        if result.returncode == 0:
            print("âœ… SUCCESS")
            if result.stdout:
                print(result.stdout)
        else:
            print("âŒ FAILED")
            if result.stderr:
                print("STDERR:", result.stderr)
            if result.stdout:
                print("STDOUT:", result.stdout)
                
        return result.returncode == 0
        
    except Exception as e:
        print(f"âŒ ERROR: {e}")
        return False

def main():
    """Main test runner following TDD workflow"""
    
    print("ğŸš€ Steele Data Transformation - Test-Driven Development Workflow")
    print("ğŸ“‹ Data Flow: Sample Data â†’ Golden Master â†’ AI-Friendly Format â†’ Final Tagged Format")
    print("=" * 80)
    
    # Change to Steele directory
    os.chdir(Path(__file__).parent)
    
    # Step 1: Run data loading tests
    success = run_command(
        "python -m pytest tests/test_steele_data_loader.py -v -m 'not slow'",
        "Phase 1: Data Loading & Validation Tests"
    )
    
    if not success:
        print("\nâŒ Data loading tests failed. Fix issues before proceeding.")
        return 1
    
    # Step 2: Run golden dataset integration tests  
    success = run_command(
        "python -m pytest tests/test_steele_golden_integration.py -v -m 'not slow'",
        "Phase 2: Golden Dataset Integration Tests"
    )
    
    if not success:
        print("\nâŒ Golden dataset integration tests failed. Fix issues before proceeding.")
        return 1
    
    # Step 3: Run transformer tests (updated for new workflow)
    success = run_command(
        "python -m pytest tests/test_steele_transformer.py -v -m 'not slow and not ai'",
        "Phase 3: AI-Friendly Format Transformation Tests"
    )
    
    if not success:
        print("\nâŒ Transformer tests failed. Fix issues before proceeding.")
        return 1
    
    # Step 4: Run product import validation tests
    success = run_command(
        "python -m pytest tests/test_product_import_validation.py -v",
        "Phase 4: Final Tagged Format & Shopify Compliance Tests"
    )
    
    if not success:
        print("\nâŒ Product import validation tests failed. Fix issues before proceeding.")
        return 1
    
    # Step 5: Run AI integration tests (if API key available)
    if os.getenv('OPENAI_API_KEY'):
        print("\nğŸ¤– OpenAI API key found - running AI integration tests")
        success = run_command(
            "python -m pytest tests/test_steele_ai_integration.py -v -m 'ai and not slow'",
            "Phase 5: AI Enhancement Integration Tests"
        )
        
        if not success:
            print("\nâš ï¸ AI integration tests failed, but continuing...")
    else:
        print("\nâš ï¸ OPENAI_API_KEY not set - skipping AI integration tests")
    
    # Step 6: Run complete pipeline integration tests
    success = run_command(
        "python -m pytest tests/test_steele_transformer.py::TestSteeleDataTransformer::test_complete_pipeline_integration -v",
        "Phase 6: Complete Pipeline Integration Test"
    )
    
    if not success:
        print("\nâŒ Complete pipeline integration tests failed.")
        return 1
    
    # Step 7: Run performance tests
    run_command(
        "python -m pytest tests/ -v -m 'performance'",
        "Phase 7: Performance Tests"
    )
    
    # Step 8: Generate coverage report
    run_command(
        "python -m pytest tests/ --cov=utils --cov-report=html --cov-report=term-missing",
        "Phase 8: Generate Test Coverage Report"
    )
    
    # Summary
    print("\n" + "="*80)
    print("ğŸ‰ COMPLETE DATA TRANSFORMATION PIPELINE - TDD WORKFLOW COMPLETE!")
    print("="*80)
    print("""
âœ… All core tests passed successfully!

ğŸ“Š Data Flow Validated:
1. âœ… Sample Data Loading & Validation
2. âœ… Golden Master Dataset Integration 
3. âœ… AI-Friendly Format Transformation (fewer tokens)
4. âœ… Final Tagged Format for Shopify
5. âœ… AI Enhancement Integration
6. âœ… Complete Pipeline Validation

ğŸ” Key Benefits of This Workflow:
âœ“ Golden dataset ensures vehicle compatibility validation
âœ“ AI-friendly format reduces token usage and costs
âœ“ Structured data flow with clear intermediate steps
âœ“ Comprehensive validation at each transformation stage
âœ“ Shopify import format compliance verified

ğŸ“ Next Steps:
1. Review test coverage report in htmlcov/index.html
2. Run complete pipeline: transformer.process_complete_pipeline()
3. Test with real data: pytest -m 'integration' (requires OPENAI_API_KEY)
4. Replicate for other vendors: copy Steele/ structure and adapt

ğŸ”„ Replication for Other Data Sources:
1. Copy Steele/ directory â†’ NewVendor/
2. Update vendor name in transformer class  
3. Modify column mappings for new data format
4. Update sample data and golden dataset paths
5. Run this same TDD workflow

ğŸ’¡ Workflow Ensures:
- Data quality through golden dataset validation
- Cost efficiency through token-optimized AI format
- Shopify compliance through final format validation
- Scalability across multiple vendor data sources

ğŸš€ Ready for production data processing!
""")
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 